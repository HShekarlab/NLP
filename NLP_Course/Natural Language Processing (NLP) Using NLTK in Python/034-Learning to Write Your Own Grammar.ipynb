{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5eec20-a53a-4fd3-8180-8a6972cf62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d396b62-6b6a-4ad7-b89e-2b4869b99724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_Default_Tagger(simple_sentence):\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    tagger = nltk.DefaultTagger(\"NN\")\n",
    "    pos_enable_tag = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5570db5d-874a-4771-a52d-4907ad1c0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_Re_Tagger(simple_sentence):\n",
    "    customer_patterns = [\n",
    "        (r\".*ing$\", \"ADJECTIVE\"),\n",
    "        (r\".*ly$\", \"ADVERB\"),\n",
    "        (r\".*ion\", \"NOUN\"),\n",
    "        (r\"(.*ate|.*en|is)$\", \"VERB\"),\n",
    "        (r\"^an$\", \"INDEFINITE-ARTICLE\"),\n",
    "        (r\"^(with|on|at)$\", \"PREPOSITION\"),\n",
    "        (r\"^\\-?[0-9]+(\\.[0-9]+)$\", \"NUMBER\"),\n",
    "        (r\".*$\", None)\n",
    "    ]\n",
    "    tagger = nltk.RegexpTagger(customer_patterns)\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    pos_enable_tags = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc5a39b-6373-4c26-987a-6f69f3d201e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_LookUp_Tagger(simple_sentence):\n",
    "    mapping = {\n",
    "        \".\": \".\",\n",
    "        \"place\": \"NN\",\n",
    "        \"on\": \"IN\",\n",
    "        \"earth\": \"NN\",\n",
    "        \"Mysore\": \"NNP\",\n",
    "        \"is\": \"VBZ\",\n",
    "        \"an\": \"DT\",\n",
    "        \"amazing\": \"JJ\"\n",
    "    }\n",
    "    tagger = nltk.UnigramTagger(model= mapping)\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    pos_enable_tag = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d48c58f-67ed-4750-a2fc-07e20e52ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mysore', 'NN'), ('is', 'NN'), ('an', 'NN'), ('amazing', 'NN'), ('place', 'NN'), ('on', 'NN'), ('earth', 'NN'), ('.', 'NN'), ('I', 'NN'), ('have', 'NN'), ('visited', 'NN'), ('Mysore', 'NN'), ('10', 'NN'), ('times', 'NN'), ('.', 'NN')]\n",
      "[('Mysore', None), ('is', 'VERB'), ('an', 'INDEFINITE-ARTICLE'), ('amazing', 'ADJECTIVE'), ('place', None), ('on', 'PREPOSITION'), ('earth', None), ('.', None), ('I', None), ('have', None), ('visited', None), ('Mysore', None), ('10', None), ('times', None), ('.', None)]\n",
      "[('Mysore', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('amazing', 'JJ'), ('place', 'NN'), ('on', 'IN'), ('earth', 'NN'), ('.', '.'), ('I', None), ('have', None), ('visited', None), ('Mysore', 'NNP'), ('10', None), ('times', None), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_sentence = \"Mysore is an amazing place on earth. I have visited Mysore 10 times.\"\n",
    "    Learn_Default_Tagger(test_sentence)\n",
    "    Learn_Re_Tagger(test_sentence)\n",
    "    Learn_LookUp_Tagger(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c29c275-b542-4ced-9316-1ed2e951af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1b736a-7317-4ca1-b1b5-5459af9e6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sample_Data():\n",
    "    return [\n",
    "        \"Paris is the capital of France.\",\n",
    "        \"Steve Jobs was the CEO of Apple.\",\n",
    "        \"iPhone was Invented by Apple.\",\n",
    "        \"Books can be purchased in Market.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41cfa871-1899-4b2e-ad56-37703d49fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Dictionary():\n",
    "    dictionary = {}\n",
    "    for sent in Sample_Data():\n",
    "        parts_of_speech_tags = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "        for tag in parts_of_speech_tags:\n",
    "            value = tag[0]\n",
    "            pos = tag[1]\n",
    "            dictionary[value] = pos\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7e2ab0-f9cf-476d-b3df-7f6d99358691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_my_Tagger(tagger, file_name):\n",
    "    file_handle = open(file_name, \"wb\")\n",
    "    pickle.dump(tagger, file_handle)\n",
    "    file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1016aa79-7e98-443d-9148-685dcecee8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_my_Traning(file_name):\n",
    "    tagger = nltk.UnigramTagger(model= Build_Dictionary())\n",
    "    Save_my_Tagger(tagger, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7390f9e8-6c4c-47cd-a41c-a615505e7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_my_Tagger(file_name):\n",
    "    return pickle.load(open(file_name, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fea732ba-c03e-4d1d-bbec-8d448dec7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Iphone is purchased by Steve Jobs in Paris Market\"\n",
    "file_name = \"my_Tagger.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f536a0-e18d-4d46-bfa7-f5e5f26f2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_my_Traning(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8a355a5-893a-403f-a6cc-dd466af7869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_Tagger = Load_my_Tagger(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f315ac2a-fab9-427f-b417-103bc8e58bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Iphone', None), ('is', 'VBZ'), ('purchased', 'VBN'), ('by', 'IN'), ('Steve', 'NNP'), ('Jobs', 'NNP'), ('in', 'IN'), ('Paris', 'NNP'), ('Market', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(my_Tagger.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2acd10-f4e0-4ddb-ac6c-896418667a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.parse.generate import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "853cd735-39d1-4c48-9845-f826e81f8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = [\n",
    "    \"ROOt -> WORD\",\n",
    "    \"WORd -> ' '\",\n",
    "    \"WORD -> NUMBER LETTER\",\n",
    "    \"WORD -> LETTER NUMBER\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "687ecdf3-d1dc-436d-a9b6-cd0955649621",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = list(string.digits)\n",
    "\n",
    "for digit in digits[:4]:\n",
    "    productions.append(\"NUMBER -> '{w}'\".format(w= digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2636117c-b06a-40c4-88e9-cdc4a92a03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = \"' | '\".join(list(string.ascii_lowercase)[:4])\n",
    "productions.append(\"LETTER -> '{w}'\".format(w= letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd0ca44c-f67d-49db-b7bb-562210da00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_string = \"\\n\".join(productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9c4382b-1f44-4066-a687-43cafc7e891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 12 productions (start state = ROOt)\n",
      "    ROOt -> WORD\n",
      "    WORd -> ' '\n",
      "    WORD -> NUMBER LETTER\n",
      "    WORD -> LETTER NUMBER\n",
      "    NUMBER -> '0'\n",
      "    NUMBER -> '1'\n",
      "    NUMBER -> '2'\n",
      "    NUMBER -> '3'\n",
      "    LETTER -> 'a'\n",
      "    LETTER -> 'b'\n",
      "    LETTER -> 'c'\n",
      "    LETTER -> 'd'\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(grammar_string)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "147a3fb1-f4ed-4a7a-94de-eea4d452c4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Word: 0a\n",
      "Generated Word: 0b\n",
      "Generated Word: 0c\n",
      "Generated Word: 0d\n",
      "Generated Word: 1a\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(grammar, n= 5, depth= 5):\n",
    "    palindrom = \"\".join(sentence).replace(\" \", \"\")\n",
    "    print(\"Generated Word: {}\".format(palindrom, len(palindrom)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
