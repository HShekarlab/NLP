{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3780ee4-0e9e-4a23-b471-12161328b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb99a21-714b-430d-964a-2d08ba7f8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_Default_Tagger(simple_sentence):\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    tagger = nltk.DefaultTagger(\"NN\")\n",
    "    pos_enable_tag = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5631d2be-20fe-4393-a33b-7552290f6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_Re_Tagger(simple_sentence):\n",
    "    customer_patterns = [\n",
    "        (r\".*ing$\", \"ADJECTIVE\"),\n",
    "        (r\".*ly$\", \"ADVERB\"),\n",
    "        (r\".*ion\", \"NOUN\"),\n",
    "        (r\"(.*ate|.*en|is)$\", \"VERB\"),\n",
    "        (r\"^an$\", \"INDEFINITE-ARTICLE\"),\n",
    "        (r\"^(with|on|at)$\", \"PREPOSITION\"),\n",
    "        (r\"^\\-?[0-9]+(\\.[0-9]+)$\", \"NUMBER\"),\n",
    "        (r\".*$\", None)\n",
    "    ]\n",
    "    tagger = nltk.RegexpTagger(customer_patterns)\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    pos_enable_tags = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f24e004-b566-415b-b1f1-9547e095f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_LookUp_Tagger(simple_sentence):\n",
    "    mapping = {\n",
    "        \".\": \".\",\n",
    "        \"place\": \"NN\",\n",
    "        \"on\": \"IN\",\n",
    "        \"earth\": \"NN\",\n",
    "        \"Mysore\": \"NNP\",\n",
    "        \"is\": \"VBZ\",\n",
    "        \"an\": \"DT\",\n",
    "        \"amazing\": \"JJ\"\n",
    "    }\n",
    "    tagger = nltk.UnigramTagger(model= mapping)\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    pos_enable_tag = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e19091-2446-4535-9e00-3221c62dfcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mysore', 'NN'), ('is', 'NN'), ('an', 'NN'), ('amazing', 'NN'), ('place', 'NN'), ('on', 'NN'), ('earth', 'NN'), ('.', 'NN'), ('I', 'NN'), ('have', 'NN'), ('visited', 'NN'), ('Mysore', 'NN'), ('10', 'NN'), ('times', 'NN'), ('.', 'NN')]\n",
      "[('Mysore', None), ('is', 'VERB'), ('an', 'INDEFINITE-ARTICLE'), ('amazing', 'ADJECTIVE'), ('place', None), ('on', 'PREPOSITION'), ('earth', None), ('.', None), ('I', None), ('have', None), ('visited', None), ('Mysore', None), ('10', None), ('times', None), ('.', None)]\n",
      "[('Mysore', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('amazing', 'JJ'), ('place', 'NN'), ('on', 'IN'), ('earth', 'NN'), ('.', '.'), ('I', None), ('have', None), ('visited', None), ('Mysore', 'NNP'), ('10', None), ('times', None), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_sentence = \"Mysore is an amazing place on earth. I have visited Mysore 10 times.\"\n",
    "    Learn_Default_Tagger(test_sentence)\n",
    "    Learn_Re_Tagger(test_sentence)\n",
    "    Learn_LookUp_Tagger(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11551ec0-1bc5-4e52-b80f-073c013de8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6c7ac6-29bd-499a-a95e-4614933ba581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sample_Data():\n",
    "    return [\n",
    "        \"Paris is the capital of France.\",\n",
    "        \"Steve Jobs was the CEO of Apple.\",\n",
    "        \"iPhone was Invented by Apple.\",\n",
    "        \"Books can be purchased in Market.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad255b53-cfe9-4303-a117-542634ae876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Dictionary():\n",
    "    dictionary = {}\n",
    "    for sent in Sample_Data():\n",
    "        parts_of_speech_tags = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "        for tag in parts_of_speech_tags:\n",
    "            value = tag[0]\n",
    "            pos = tag[1]\n",
    "            dictionary[value] = pos\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81b21cc-a3c6-49b0-a6df-5faa622d879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_my_Tagger(tagger, file_name):\n",
    "    file_handle = open(file_name, \"wb\")\n",
    "    pickle.dump(tagger, file_handle)\n",
    "    file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d0ea6fb-202c-4da6-bae7-b8b90734f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_my_Traning(file_name):\n",
    "    tagger = nltk.UnigramTagger(model= Build_Dictionary())\n",
    "    Save_my_Tagger(tagger, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "674ced34-ee2a-4c60-ad22-b8aa77acdda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_my_Tagger(file_name):\n",
    "    return pickle.load(open(file_name, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8053c84-8c91-422e-8bc3-1da4a4d735e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Iphone is purchased by Steve Jobs in Paris Market\"\n",
    "file_name = \"my_Tagger.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "674c943d-90ab-475c-8661-8f85f1461e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_my_Traning(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec536ba-2d04-4faf-be62-03708ec39009",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_Tagger = Load_my_Tagger(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e7b05f5-9cb5-429c-b938-911e329a8f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Iphone', None), ('is', 'VBZ'), ('purchased', 'VBN'), ('by', 'IN'), ('Steve', 'NNP'), ('Jobs', 'NNP'), ('in', 'IN'), ('Paris', 'NNP'), ('Market', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(my_Tagger.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd3b01be-d662-49df-bf66-7b5d5aa4a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.parse.generate import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16d4ddcf-bde2-403a-80c1-2a9b03742da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = [\n",
    "    \"ROOt -> WORD\",\n",
    "    \"WORd -> ' '\",\n",
    "    \"WORD -> NUMBER LETTER\",\n",
    "    \"WORD -> LETTER NUMBER\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdb48159-b514-46cf-ac32-008f49e4f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = list(string.digits)\n",
    "\n",
    "for digit in digits[:4]:\n",
    "    productions.append(\"NUMBER -> '{w}'\".format(w= digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15fce39a-6a51-4bb0-b1c5-45666c2bb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = \"' | '\".join(list(string.ascii_lowercase)[:4])\n",
    "productions.append(\"LETTER -> '{w}'\".format(w= letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08f57f51-f3b8-4b12-9f6f-bc31e48d9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_string = \"\\n\".join(productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d16c0a6-f6df-464b-ac4f-6ceff22bc18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 12 productions (start state = ROOt)\n",
      "    ROOt -> WORD\n",
      "    WORd -> ' '\n",
      "    WORD -> NUMBER LETTER\n",
      "    WORD -> LETTER NUMBER\n",
      "    NUMBER -> '0'\n",
      "    NUMBER -> '1'\n",
      "    NUMBER -> '2'\n",
      "    NUMBER -> '3'\n",
      "    LETTER -> 'a'\n",
      "    LETTER -> 'b'\n",
      "    LETTER -> 'c'\n",
      "    LETTER -> 'd'\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(grammar_string)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d98199ed-542f-4864-9337-6fbda758ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Word: 0a\n",
      "Generated Word: 0b\n",
      "Generated Word: 0c\n",
      "Generated Word: 0d\n",
      "Generated Word: 1a\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(grammar, n= 5, depth= 5):\n",
    "    palindrom = \"\".join(sentence).replace(\" \", \"\")\n",
    "    print(\"Generated Word: {}\".format(palindrom, len(palindrom)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25a540e3-73aa-4361-94f6-a1f0aed76612",
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = [\n",
    "    \"ROOT -> WORD [1.0]\",\n",
    "    \"WORD -> P1 P2 [0.25]\",\n",
    "    \"WORD -> P1 P2 [0.25]\",\n",
    "    \"WORD -> P1 P2 P3 [0.25]\",\n",
    "    \"WORD -> P1 P2 P3 P4 [0.25]\",\n",
    "    \"P1 -> 'A' [1.0]\",\n",
    "    \"P2 -> 'B' [0.5]\",\n",
    "    \"P2 -> 'C' [0.5]\",\n",
    "    \"P3 -> 'D' [0.3]\",\n",
    "    \"P3 -> 'E' [0.3]\",\n",
    "    \"P3 -> 'F' [0.4]\",\n",
    "    \"P4 -> 'G' [0.9]\",\n",
    "    \"P4 -> 'H' [0.1]\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85bb48c0-0a7b-4a24-b325-7eded58c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_string = \"\\n\".join(productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1107b3b7-2fd9-45aa-afba-c5151a9c8e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 13 productions (start state = ROOT)\n",
      "    ROOT -> WORD [1.0]\n",
      "    WORD -> P1 P2 [0.25]\n",
      "    WORD -> P1 P2 [0.25]\n",
      "    WORD -> P1 P2 P3 [0.25]\n",
      "    WORD -> P1 P2 P3 P4 [0.25]\n",
      "    P1 -> 'A' [1.0]\n",
      "    P2 -> 'B' [0.5]\n",
      "    P2 -> 'C' [0.5]\n",
      "    P3 -> 'D' [0.3]\n",
      "    P3 -> 'E' [0.3]\n",
      "    P3 -> 'F' [0.4]\n",
      "    P4 -> 'G' [0.9]\n",
      "    P4 -> 'H' [0.1]\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.PCFG.fromstring(grammar_string)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fb898f0-5a6a-45e3-b23b-8b8db1aae8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: AB, Size: 2\n",
      "String: AC, Size: 2\n",
      "String: AB, Size: 2\n",
      "String: AC, Size: 2\n",
      "String: ABD, Size: 3\n",
      "String: ABE, Size: 3\n",
      "String: ABF, Size: 3\n",
      "String: ACD, Size: 3\n",
      "String: ACE, Size: 3\n",
      "String: ACF, Size: 3\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(grammar, n= 10, depth= 5):\n",
    "    palindrom = \"\".join(sentence).replace(\" \", \"\")\n",
    "    print(\"String: {}, Size: {}\".format(palindrom, len(palindrom)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
