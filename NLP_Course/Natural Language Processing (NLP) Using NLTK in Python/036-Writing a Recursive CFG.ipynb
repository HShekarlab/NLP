{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d51265b-cf84-4fb1-afb8-f7f53f3712e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0d2332-4d09-415f-90d9-865d5ff5fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_Default_Tagger(simple_sentence):\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    tagger = nltk.DefaultTagger(\"NN\")\n",
    "    pos_enable_tag = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f348615f-88b2-4394-a23d-a40f80680eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_Re_Tagger(simple_sentence):\n",
    "    customer_patterns = [\n",
    "        (r\".*ing$\", \"ADJECTIVE\"),\n",
    "        (r\".*ly$\", \"ADVERB\"),\n",
    "        (r\".*ion\", \"NOUN\"),\n",
    "        (r\"(.*ate|.*en|is)$\", \"VERB\"),\n",
    "        (r\"^an$\", \"INDEFINITE-ARTICLE\"),\n",
    "        (r\"^(with|on|at)$\", \"PREPOSITION\"),\n",
    "        (r\"^\\-?[0-9]+(\\.[0-9]+)$\", \"NUMBER\"),\n",
    "        (r\".*$\", None)\n",
    "    ]\n",
    "    tagger = nltk.RegexpTagger(customer_patterns)\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    pos_enable_tags = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148aafcb-4830-4b44-8cff-df8d71009ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_LookUp_Tagger(simple_sentence):\n",
    "    mapping = {\n",
    "        \".\": \".\",\n",
    "        \"place\": \"NN\",\n",
    "        \"on\": \"IN\",\n",
    "        \"earth\": \"NN\",\n",
    "        \"Mysore\": \"NNP\",\n",
    "        \"is\": \"VBZ\",\n",
    "        \"an\": \"DT\",\n",
    "        \"amazing\": \"JJ\"\n",
    "    }\n",
    "    tagger = nltk.UnigramTagger(model= mapping)\n",
    "    words_in_sentence = nltk.word_tokenize(simple_sentence)\n",
    "    pos_enable_tag = tagger.tag(words_in_sentence)\n",
    "    print(pos_enable_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4d33b3-768f-4ac0-b40c-6b556fbd73ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mysore', 'NN'), ('is', 'NN'), ('an', 'NN'), ('amazing', 'NN'), ('place', 'NN'), ('on', 'NN'), ('earth', 'NN'), ('.', 'NN'), ('I', 'NN'), ('have', 'NN'), ('visited', 'NN'), ('Mysore', 'NN'), ('10', 'NN'), ('times', 'NN'), ('.', 'NN')]\n",
      "[('Mysore', None), ('is', 'VERB'), ('an', 'INDEFINITE-ARTICLE'), ('amazing', 'ADJECTIVE'), ('place', None), ('on', 'PREPOSITION'), ('earth', None), ('.', None), ('I', None), ('have', None), ('visited', None), ('Mysore', None), ('10', None), ('times', None), ('.', None)]\n",
      "[('Mysore', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('amazing', 'JJ'), ('place', 'NN'), ('on', 'IN'), ('earth', 'NN'), ('.', '.'), ('I', None), ('have', None), ('visited', None), ('Mysore', 'NNP'), ('10', None), ('times', None), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_sentence = \"Mysore is an amazing place on earth. I have visited Mysore 10 times.\"\n",
    "    Learn_Default_Tagger(test_sentence)\n",
    "    Learn_Re_Tagger(test_sentence)\n",
    "    Learn_LookUp_Tagger(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a8f30a-8b9d-4ccd-8478-c1b75e0ffeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae23632-801d-4f55-a61f-7763496d55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sample_Data():\n",
    "    return [\n",
    "        \"Paris is the capital of France.\",\n",
    "        \"Steve Jobs was the CEO of Apple.\",\n",
    "        \"iPhone was Invented by Apple.\",\n",
    "        \"Books can be purchased in Market.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723032fc-2b5b-4f48-83b5-33fe88159e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Dictionary():\n",
    "    dictionary = {}\n",
    "    for sent in Sample_Data():\n",
    "        parts_of_speech_tags = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "        for tag in parts_of_speech_tags:\n",
    "            value = tag[0]\n",
    "            pos = tag[1]\n",
    "            dictionary[value] = pos\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f92a04b-18ed-450e-99ea-3a7148b73df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_my_Tagger(tagger, file_name):\n",
    "    file_handle = open(file_name, \"wb\")\n",
    "    pickle.dump(tagger, file_handle)\n",
    "    file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d6416a-3bf6-41ae-b929-27a812b5a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_my_Traning(file_name):\n",
    "    tagger = nltk.UnigramTagger(model= Build_Dictionary())\n",
    "    Save_my_Tagger(tagger, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead3337f-9a89-423e-8fd6-cd7b7c14d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_my_Tagger(file_name):\n",
    "    return pickle.load(open(file_name, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9621a835-acf6-4a49-a702-91379bd15ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Iphone is purchased by Steve Jobs in Paris Market\"\n",
    "file_name = \"my_Tagger.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cdc9100-15be-4aef-96e7-548bf7304832",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_my_Traning(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614440f0-9bb3-45b1-aa8e-643d29a8ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_Tagger = Load_my_Tagger(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a027b4d7-1358-43d2-bd5f-e5f2624e9653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Iphone', None), ('is', 'VBZ'), ('purchased', 'VBN'), ('by', 'IN'), ('Steve', 'NNP'), ('Jobs', 'NNP'), ('in', 'IN'), ('Paris', 'NNP'), ('Market', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(my_Tagger.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa1eee2-e779-4f97-ba9b-5543e5ac0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.parse.generate import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc70b4a0-3b3c-46bb-af93-2712d67f2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = [\n",
    "    \"ROOt -> WORD\",\n",
    "    \"WORd -> ' '\",\n",
    "    \"WORD -> NUMBER LETTER\",\n",
    "    \"WORD -> LETTER NUMBER\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d60ecb4-43d7-4881-92fc-5372481f01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = list(string.digits)\n",
    "\n",
    "for digit in digits[:4]:\n",
    "    productions.append(\"NUMBER -> '{w}'\".format(w= digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86ef5c09-5d6f-49a6-a30e-639849b6feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = \"' | '\".join(list(string.ascii_lowercase)[:4])\n",
    "productions.append(\"LETTER -> '{w}'\".format(w= letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7589c1bb-89a4-4e3b-be73-a929007bf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_string = \"\\n\".join(productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bdf7f0b-9c19-480b-b07b-d5956be3743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 12 productions (start state = ROOt)\n",
      "    ROOt -> WORD\n",
      "    WORd -> ' '\n",
      "    WORD -> NUMBER LETTER\n",
      "    WORD -> LETTER NUMBER\n",
      "    NUMBER -> '0'\n",
      "    NUMBER -> '1'\n",
      "    NUMBER -> '2'\n",
      "    NUMBER -> '3'\n",
      "    LETTER -> 'a'\n",
      "    LETTER -> 'b'\n",
      "    LETTER -> 'c'\n",
      "    LETTER -> 'd'\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(grammar_string)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7886f722-701a-4d6c-90b5-7aacd9bafebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Word: 0a\n",
      "Generated Word: 0b\n",
      "Generated Word: 0c\n",
      "Generated Word: 0d\n",
      "Generated Word: 1a\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(grammar, n= 5, depth= 5):\n",
    "    palindrom = \"\".join(sentence).replace(\" \", \"\")\n",
    "    print(\"Generated Word: {}\".format(palindrom, len(palindrom)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce608d26-9d1d-4bdc-9ab1-d55b599b611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = [\n",
    "    \"ROOT -> WORD [1.0]\",\n",
    "    \"WORD -> P1 P2 [0.25]\",\n",
    "    \"WORD -> P1 P2 [0.25]\",\n",
    "    \"WORD -> P1 P2 P3 [0.25]\",\n",
    "    \"WORD -> P1 P2 P3 P4 [0.25]\",\n",
    "    \"P1 -> 'A' [1.0]\",\n",
    "    \"P2 -> 'B' [0.5]\",\n",
    "    \"P2 -> 'C' [0.5]\",\n",
    "    \"P3 -> 'D' [0.3]\",\n",
    "    \"P3 -> 'E' [0.3]\",\n",
    "    \"P3 -> 'F' [0.4]\",\n",
    "    \"P4 -> 'G' [0.9]\",\n",
    "    \"P4 -> 'H' [0.1]\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a368ac74-2600-4c13-9faf-0cbe001d8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_string = \"\\n\".join(productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "228edfe5-6e8f-42b7-9218-c056b5a90202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 13 productions (start state = ROOT)\n",
      "    ROOT -> WORD [1.0]\n",
      "    WORD -> P1 P2 [0.25]\n",
      "    WORD -> P1 P2 [0.25]\n",
      "    WORD -> P1 P2 P3 [0.25]\n",
      "    WORD -> P1 P2 P3 P4 [0.25]\n",
      "    P1 -> 'A' [1.0]\n",
      "    P2 -> 'B' [0.5]\n",
      "    P2 -> 'C' [0.5]\n",
      "    P3 -> 'D' [0.3]\n",
      "    P3 -> 'E' [0.3]\n",
      "    P3 -> 'F' [0.4]\n",
      "    P4 -> 'G' [0.9]\n",
      "    P4 -> 'H' [0.1]\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.PCFG.fromstring(grammar_string)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a606429-3a35-41d2-b1c4-b82f9b29b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: AB, Size: 2\n",
      "String: AC, Size: 2\n",
      "String: AB, Size: 2\n",
      "String: AC, Size: 2\n",
      "String: ABD, Size: 3\n",
      "String: ABE, Size: 3\n",
      "String: ABF, Size: 3\n",
      "String: ACD, Size: 3\n",
      "String: ACE, Size: 3\n",
      "String: ACF, Size: 3\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(grammar, n= 10, depth= 5):\n",
    "    palindrom = \"\".join(sentence).replace(\" \", \"\")\n",
    "    print(\"String: {}, Size: {}\".format(palindrom, len(palindrom)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9f1764b-820a-4b7d-93f2-911abf4344ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = [\n",
    "    \"ROOT -> WORD\",\n",
    "    \"WORD -> ' '\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23635188-6982-4fae-8da1-7b0fe5a811ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = list(string.digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "144b1722-e4ff-4096-a6ea-06e285ff81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alphabet in alphabets:\n",
    "    productions.append(\"WORD -> '{w}' WORD '{w}'\".format(w= alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5072d708-0cc0-4632-a05e-22c051c7c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_string = \"\\n\".join(productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efb080e5-3269-4068-aea6-e063c55ec3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 12 productions (start state = ROOT)\n",
      "    ROOT -> WORD\n",
      "    WORD -> ' '\n",
      "    WORD -> '0' WORD '0'\n",
      "    WORD -> '1' WORD '1'\n",
      "    WORD -> '2' WORD '2'\n",
      "    WORD -> '3' WORD '3'\n",
      "    WORD -> '4' WORD '4'\n",
      "    WORD -> '5' WORD '5'\n",
      "    WORD -> '6' WORD '6'\n",
      "    WORD -> '7' WORD '7'\n",
      "    WORD -> '8' WORD '8'\n",
      "    WORD -> '9' WORD '9'\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(grammar_string)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "097c6992-a225-4836-a80f-06c05af1aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: , Size: 0\n",
      "String: 00, Size: 2\n",
      "String: 0000, Size: 4\n",
      "String: 0110, Size: 4\n",
      "String: 0220, Size: 4\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(grammar, n= 5, depth= 5):\n",
    "    palindrom = \"\".join(sentence).replace(\" \", \"\")\n",
    "    print(\"String: {}, Size: {}\".format(palindrom, len(palindrom)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
